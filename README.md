# Are-you-a-smoker-or-non-smoker-
Deciding smoking habits of survey participants considering the answers they gave to non-related questions

Project (Signature Assignment)
The signature project provides you with an opportunity to complete a substantial effort where you showcase your understanding of the machine learning and data mining techniques studied in the course.

Identify a data set that you want to explore and for which you can build a minimum of three appropriate and useful machine learning or data mining models.

Your effort must follow the CRISP-DM process and addresses business understanding, definition of the problem to be solved, data sources, data cleaning efforts, assessment of data quality, exploration of the data, transformations, imputation, case elimination, training vs validation data set division strategy, model selection, model tuning, evaluation, accuracy, etc.

Explain in detail what you did, show your R code in an R Notebook, and explain why you chose this approach versus other possible approaches.
Your models must be evaluated and compared using appropriate methods, e.g., MAD, MSE, RMSE, accuracy, AUC, R-Squared, etc.
You must construct an ensemble learner from your models and also evaluate the ensemble.
You must provide justification, interpretation, evaluation, evidence for all your work. Don't simply provide the R output - you must interpret the output and evaluate it.
Here are key things to keep in mind for the project that will lose you points. Use this rubric for self-evaluation.
where does the data come from?
how do you plan on assessing data quality and deal with missing values?
what strategy are you using for data imputation and why? if the data set has no missing data, can you randomly remove data and then impute the data and compare performance of your algorithms with imputed vs full data? why do they differ? how do they differ?
how do you assess normality, distribution, skew -- and does it matter for your algorithms?
what kinds of exploratory data analysis and visualization do you plan on doing?
what kind of normalization, standardization, regularization, or transformation do you plan on using and why?
how will you select the features? will you use PCA?
what kind of feature engineering will you use? will you add new derived features?
what do you plan on predicting?
which algorithms will you use and why?
naive bayes, knn, decision trees, rules, log regression, multi regression, lasso, ridge, neural net, svm, clustering
how do you compare and evaluate the performance of the algorithms? R-Squared? MAD, MSE, RMSE? AIC? AUC? why are they that way?
how do you choose training vs validation data? why?
can you and should you use k-fold cross-validation?
how would you build a stacked ensemble model? is it a better model? can you use boosting or bagging? or build a stacked learner?
how will you communicate the results of your algorithms?
Submission Details
Submit an R Notebook containing all of your code and explanations structured using the CRISP-DM model. Submit the .nb as well as the .nb.html output of your notebook. Upload this along with your data set (or a link) to Blackboard under Assignments/Project.
Submit a (clickable) link to a video presentation demonstrating your working code in the comments section on Blackboard under Assignments/Project, an explanation of your project, your data set, and (optional) slides summarizing your findings. It must show you doing the demonstration. Upload the video to YouTube or another video sharing site and submit a link, not the actual video. Below are some tools and strategies for creating screen narrations. Keep the presentation to a maximum of 10 minutes. 
Submit a (public and clickable) link to the completed rubric for self-evaluation (make a copy of the rubric, do not request access to the rubric via Google) in the comments section on Blackboard under Assignments/Project so we can see exactly what you did. Fill in the column for the points you "deserve" based on the work you've done. Tell us where in your R Notebook we can find that work - and note in the comments anything that does not work. 
Post a (clickable) link to your video only to the group discussion board in your group's thread so your peer's can see what you did. Provide peer feedback to everyone in your group. Feedback is required and if not provided will result in a grade of 0 and an F for the course.
Note that a random number of students will be required to provide an in-person demonstration of your project via Skype, join.me, or Google Hangouts with question and answer. If you are selected, you are required to do a live demonstration - failure to do so will result in a grade of 0 and an F for the course.
If your files are too big to upload to Blackboard, zip (not rar) them and provide a link to your work on Google Drive, OneDrive, or some other file sharing site.
A video presentation is required; failure to submit a video presentation is 50% reduction in the final grade for the project.
We expect to find copious comments, justifications, evidence, references, interpretations in your R Notebooks. Remember, it's not just about getting some function or package to work -- you must tell us what the results mean.
